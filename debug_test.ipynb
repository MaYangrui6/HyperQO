{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80bf06e4-de16-422f-89b4-d238f3586dfc",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-02-29T07:43:57.880357Z",
     "start_time": "2024-02-29T07:42:59.287043Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5117/3932973385.py:41: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  init.uniform(param)\n",
      "/tmp/ipykernel_5117/3932973385.py:39: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  init.xavier_normal(param)\n",
      "2024-02-29 15:43:12,644 : INFO : adding document #0 to Dictionary<0 unique tokens: []>\n",
      "2024-02-29 15:43:12,929 : INFO : adding document #10000 to Dictionary<134 unique tokens: ['Index_Scan_customer_demographics_Filter_cd_gender=ANDcd_marital_status=ANDcd_education_status=Index_Cond_cd_demo_sk=store_sales.ss_cdemo_sk', 'Seq_Scan_date_dim_Filter_d_year=', 'Seq_Scan_promotion_Filter_p_channel_email=ORp_channel_event=', 'Index_Scan_customer_address_Filter_ca_country=ANDca_state=ANYORca_state=ANYORca_state=ANYANDca_state=ANYANDstore_sales.ss_net_profit>=ANDstore_sales.ss_net_profit<=ORca_state=ANYANDstore_sales.ss_net_profit>=ANDstore_sales.ss_net_profit<=ORca_state=ANYANDstore_sales.ss_net_profit>=ANDstore_sales.ss_net_profit<=Index_Cond_ca_address_sk=store_sales.ss_addr_sk', 'Index_Scan_customer_demographics_Filter_cd_marital_status=ANDcd_education_status=ORcd_marital_status=ANDcd_education_status=ORcd_marital_status=ANDcd_education_status=ANDcd_marital_status=ANDcd_education_status=ANDstore_sales.ss_sales_price>=.ANDstore_sales.ss_sales_price<=.ORcd_marital_status=ANDcd_education_status=ANDstore_sales.ss_sales_price>=.ANDstore_sales.ss_sales_price<=.ORcd_marital_status=ANDcd_education_status=ANDstore_sales.ss_sales_price>=.ANDstore_sales.ss_sales_price<=.Index_Cond_cd_demo_sk=store_sales.ss_cdemo_sk']...>\n",
      "2024-02-29 15:43:13,056 : INFO : built Dictionary<134 unique tokens: ['Index_Scan_customer_demographics_Filter_cd_gender=ANDcd_marital_status=ANDcd_education_status=Index_Cond_cd_demo_sk=store_sales.ss_cdemo_sk', 'Seq_Scan_date_dim_Filter_d_year=', 'Seq_Scan_promotion_Filter_p_channel_email=ORp_channel_event=', 'Index_Scan_customer_address_Filter_ca_country=ANDca_state=ANYORca_state=ANYORca_state=ANYANDca_state=ANYANDstore_sales.ss_net_profit>=ANDstore_sales.ss_net_profit<=ORca_state=ANYANDstore_sales.ss_net_profit>=ANDstore_sales.ss_net_profit<=ORca_state=ANYANDstore_sales.ss_net_profit>=ANDstore_sales.ss_net_profit<=Index_Cond_ca_address_sk=store_sales.ss_addr_sk', 'Index_Scan_customer_demographics_Filter_cd_marital_status=ANDcd_education_status=ORcd_marital_status=ANDcd_education_status=ORcd_marital_status=ANDcd_education_status=ANDcd_marital_status=ANDcd_education_status=ANDstore_sales.ss_sales_price>=.ANDstore_sales.ss_sales_price<=.ORcd_marital_status=ANDcd_education_status=ANDstore_sales.ss_sales_price>=.ANDstore_sales.ss_sales_price<=.ORcd_marital_status=ANDcd_education_status=ANDstore_sales.ss_sales_price>=.ANDstore_sales.ss_sales_price<=.Index_Cond_cd_demo_sk=store_sales.ss_cdemo_sk']...> from 14400 documents (total 51200 corpus positions)\n",
      "2024-02-29 15:43:13,081 : INFO : Dictionary lifecycle event {'msg': \"built Dictionary<134 unique tokens: ['Index_Scan_customer_demographics_Filter_cd_gender=ANDcd_marital_status=ANDcd_education_status=Index_Cond_cd_demo_sk=store_sales.ss_cdemo_sk', 'Seq_Scan_date_dim_Filter_d_year=', 'Seq_Scan_promotion_Filter_p_channel_email=ORp_channel_event=', 'Index_Scan_customer_address_Filter_ca_country=ANDca_state=ANYORca_state=ANYORca_state=ANYANDca_state=ANYANDstore_sales.ss_net_profit>=ANDstore_sales.ss_net_profit<=ORca_state=ANYANDstore_sales.ss_net_profit>=ANDstore_sales.ss_net_profit<=ORca_state=ANYANDstore_sales.ss_net_profit>=ANDstore_sales.ss_net_profit<=Index_Cond_ca_address_sk=store_sales.ss_addr_sk', 'Index_Scan_customer_demographics_Filter_cd_marital_status=ANDcd_education_status=ORcd_marital_status=ANDcd_education_status=ORcd_marital_status=ANDcd_education_status=ANDcd_marital_status=ANDcd_education_status=ANDstore_sales.ss_sales_price>=.ANDstore_sales.ss_sales_price<=.ORcd_marital_status=ANDcd_education_status=ANDstore_sales.ss_sales_price>=.ANDstore_sales.ss_sales_price<=.ORcd_marital_status=ANDcd_education_status=ANDstore_sales.ss_sales_price>=.ANDstore_sales.ss_sales_price<=.Index_Cond_cd_demo_sk=store_sales.ss_cdemo_sk']...> from 14400 documents (total 51200 corpus positions)\", 'datetime': '2024-02-29T15:43:13.081608', 'gensim': '4.2.0', 'python': '3.8.18 (default, Sep 11 2023, 13:40:15) \\n[GCC 11.2.0]', 'platform': 'Linux-4.19.0-9.ucloud-x86_64-with-glibc2.17', 'event': 'created'}\n",
      "2024-02-29 15:43:13,353 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d20,n5,w5,mc3,s0.001,t3>', 'datetime': '2024-02-29T15:43:13.353682', 'gensim': '4.2.0', 'python': '3.8.18 (default, Sep 11 2023, 13:40:15) \\n[GCC 11.2.0]', 'platform': 'Linux-4.19.0-9.ucloud-x86_64-with-glibc2.17', 'event': 'created'}\n",
      "2024-02-29 15:43:13,370 : INFO : collecting all words and their counts\n",
      "2024-02-29 15:43:13,372 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2024-02-29 15:43:13,441 : INFO : PROGRESS: at example #10000, processed 35466 words (521588 words/s), 134 word types, 0 tags\n",
      "2024-02-29 15:43:13,473 : INFO : collected 134 word types and 14400 unique tags from a corpus of 14400 examples and 51200 words\n",
      "2024-02-29 15:43:13,485 : INFO : Creating a fresh vocabulary\n",
      "2024-02-29 15:43:13,487 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=3 retains 134 unique words (100.00% of original 134, drops 0)', 'datetime': '2024-02-29T15:43:13.487136', 'gensim': '4.2.0', 'python': '3.8.18 (default, Sep 11 2023, 13:40:15) \\n[GCC 11.2.0]', 'platform': 'Linux-4.19.0-9.ucloud-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}\n",
      "2024-02-29 15:43:13,488 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 51200 word corpus (100.00% of original 51200, drops 0)', 'datetime': '2024-02-29T15:43:13.488564', 'gensim': '4.2.0', 'python': '3.8.18 (default, Sep 11 2023, 13:40:15) \\n[GCC 11.2.0]', 'platform': 'Linux-4.19.0-9.ucloud-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}\n",
      "2024-02-29 15:43:13,490 : INFO : deleting the raw counts dictionary of 134 items\n",
      "2024-02-29 15:43:13,500 : INFO : sample=0.001 downsamples 127 most-common words\n",
      "2024-02-29 15:43:13,501 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 23695.320384657447 word corpus (46.3%% of prior 51200)', 'datetime': '2024-02-29T15:43:13.501725', 'gensim': '4.2.0', 'python': '3.8.18 (default, Sep 11 2023, 13:40:15) \\n[GCC 11.2.0]', 'platform': 'Linux-4.19.0-9.ucloud-x86_64-with-glibc2.17', 'event': 'prepare_vocab'}\n",
      "2024-02-29 15:43:13,503 : INFO : estimated required memory for 134 words and 20 dimensions: 4120440 bytes\n",
      "2024-02-29 15:43:13,515 : INFO : resetting layer weights\n",
      "2024-02-29 15:43:13,518 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 134 vocabulary and 20 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-02-29T15:43:13.518413', 'gensim': '4.2.0', 'python': '3.8.18 (default, Sep 11 2023, 13:40:15) \\n[GCC 11.2.0]', 'platform': 'Linux-4.19.0-9.ucloud-x86_64-with-glibc2.17', 'event': 'train'}\n",
      "2024-02-29 15:43:14,575 : INFO : EPOCH 0 - PROGRESS: at 79.95% examples, 30280 words/s, in_qsize 1, out_qsize 1\n",
      "2024-02-29 15:43:14,590 : INFO : EPOCH 0: training on 51200 raw words (38135 effective words) took 1.0s, 37146 effective words/s\n",
      "2024-02-29 15:43:15,734 : INFO : EPOCH 1 - PROGRESS: at 80.89% examples, 27602 words/s, in_qsize 1, out_qsize 1\n",
      "2024-02-29 15:43:15,738 : INFO : EPOCH 1: training on 51200 raw words (38266 effective words) took 1.1s, 33956 effective words/s\n",
      "2024-02-29 15:43:16,609 : INFO : EPOCH 2: training on 51200 raw words (38089 effective words) took 0.8s, 46055 effective words/s\n",
      "2024-02-29 15:43:17,574 : INFO : EPOCH 3: training on 51200 raw words (38069 effective words) took 0.9s, 40854 effective words/s\n",
      "2024-02-29 15:43:18,514 : INFO : EPOCH 4: training on 51200 raw words (38227 effective words) took 0.9s, 42809 effective words/s\n",
      "2024-02-29 15:43:19,556 : INFO : EPOCH 5 - PROGRESS: at 79.95% examples, 30319 words/s, in_qsize 1, out_qsize 0\n",
      "2024-02-29 15:43:19,562 : INFO : EPOCH 5: training on 51200 raw words (38076 effective words) took 1.0s, 37585 effective words/s\n",
      "2024-02-29 15:43:20,700 : INFO : EPOCH 6 - PROGRESS: at 79.95% examples, 27566 words/s, in_qsize 1, out_qsize 0\n",
      "2024-02-29 15:43:20,701 : INFO : EPOCH 6: training on 51200 raw words (38121 effective words) took 1.1s, 34305 effective words/s\n",
      "2024-02-29 15:43:21,792 : INFO : EPOCH 7 - PROGRESS: at 79.95% examples, 29672 words/s, in_qsize 1, out_qsize 1\n",
      "2024-02-29 15:43:21,800 : INFO : EPOCH 7: training on 51200 raw words (38218 effective words) took 1.0s, 36695 effective words/s\n",
      "2024-02-29 15:43:22,911 : INFO : EPOCH 8 - PROGRESS: at 80.89% examples, 28592 words/s, in_qsize 1, out_qsize 1\n",
      "2024-02-29 15:43:22,941 : INFO : EPOCH 8: training on 51200 raw words (38115 effective words) took 1.1s, 34444 effective words/s\n",
      "2024-02-29 15:43:24,038 : INFO : EPOCH 9 - PROGRESS: at 80.89% examples, 28709 words/s, in_qsize 1, out_qsize 1\n",
      "2024-02-29 15:43:24,043 : INFO : EPOCH 9: training on 51200 raw words (38046 effective words) took 1.1s, 35348 effective words/s\n",
      "2024-02-29 15:43:25,315 : INFO : EPOCH 10 - PROGRESS: at 79.95% examples, 25742 words/s, in_qsize 1, out_qsize 0\n",
      "2024-02-29 15:43:25,334 : INFO : EPOCH 10: training on 51200 raw words (38023 effective words) took 1.2s, 31533 effective words/s\n",
      "2024-02-29 15:43:26,586 : INFO : EPOCH 11 - PROGRESS: at 79.95% examples, 25280 words/s, in_qsize 1, out_qsize 1\n",
      "2024-02-29 15:43:26,590 : INFO : EPOCH 11: training on 51200 raw words (38051 effective words) took 1.2s, 31395 effective words/s\n",
      "2024-02-29 15:43:27,791 : INFO : EPOCH 12 - PROGRESS: at 79.95% examples, 26733 words/s, in_qsize 1, out_qsize 1\n",
      "2024-02-29 15:43:27,807 : INFO : EPOCH 12: training on 51200 raw words (38300 effective words) took 1.2s, 32824 effective words/s\n",
      "2024-02-29 15:43:28,806 : INFO : EPOCH 13: training on 51200 raw words (38143 effective words) took 1.0s, 39875 effective words/s\n",
      "2024-02-29 15:43:29,855 : INFO : EPOCH 14: training on 51200 raw words (38105 effective words) took 1.0s, 38339 effective words/s\n",
      "2024-02-29 15:43:31,099 : INFO : EPOCH 15 - PROGRESS: at 79.95% examples, 25748 words/s, in_qsize 1, out_qsize 1\n",
      "2024-02-29 15:43:31,106 : INFO : EPOCH 15: training on 51200 raw words (38151 effective words) took 1.2s, 31856 effective words/s\n",
      "2024-02-29 15:43:32,152 : INFO : EPOCH 16: training on 51200 raw words (38189 effective words) took 1.0s, 38190 effective words/s\n",
      "2024-02-29 15:43:33,336 : INFO : EPOCH 17 - PROGRESS: at 79.95% examples, 26923 words/s, in_qsize 1, out_qsize 0\n",
      "2024-02-29 15:43:33,344 : INFO : EPOCH 17: training on 51200 raw words (38129 effective words) took 1.1s, 33353 effective words/s\n",
      "2024-02-29 15:43:34,400 : INFO : EPOCH 18 - PROGRESS: at 79.95% examples, 30299 words/s, in_qsize 1, out_qsize 1\n",
      "2024-02-29 15:43:34,403 : INFO : EPOCH 18: training on 51200 raw words (38048 effective words) took 1.0s, 37606 effective words/s\n",
      "2024-02-29 15:43:35,380 : INFO : EPOCH 19: training on 51200 raw words (37952 effective words) took 0.9s, 40279 effective words/s\n",
      "2024-02-29 15:43:36,517 : INFO : EPOCH 20 - PROGRESS: at 79.95% examples, 27445 words/s, in_qsize 1, out_qsize 1\n",
      "2024-02-29 15:43:36,545 : INFO : EPOCH 20: training on 51200 raw words (38005 effective words) took 1.1s, 33434 effective words/s\n",
      "2024-02-29 15:43:37,686 : INFO : EPOCH 21 - PROGRESS: at 79.95% examples, 27946 words/s, in_qsize 1, out_qsize 0\n",
      "2024-02-29 15:43:37,688 : INFO : EPOCH 21: training on 51200 raw words (38180 effective words) took 1.1s, 34758 effective words/s\n",
      "2024-02-29 15:43:38,748 : INFO : EPOCH 22 - PROGRESS: at 100.00% examples, 37981 words/s, in_qsize 0, out_qsize 1\n",
      "2024-02-29 15:43:38,751 : INFO : EPOCH 22: training on 51200 raw words (38051 effective words) took 1.0s, 37888 effective words/s\n",
      "2024-02-29 15:43:39,840 : INFO : EPOCH 23 - PROGRESS: at 100.00% examples, 36645 words/s, in_qsize 0, out_qsize 0\n",
      "2024-02-29 15:43:39,841 : INFO : EPOCH 23: training on 51200 raw words (38272 effective words) took 1.0s, 36608 effective words/s\n",
      "2024-02-29 15:43:41,010 : INFO : EPOCH 24 - PROGRESS: at 80.89% examples, 27669 words/s, in_qsize 1, out_qsize 1\n",
      "2024-02-29 15:43:41,020 : INFO : EPOCH 24: training on 51200 raw words (38015 effective words) took 1.1s, 33970 effective words/s\n",
      "2024-02-29 15:43:42,203 : INFO : EPOCH 25 - PROGRESS: at 79.95% examples, 26766 words/s, in_qsize 1, out_qsize 0\n",
      "2024-02-29 15:43:42,272 : INFO : EPOCH 25: training on 51200 raw words (38152 effective words) took 1.2s, 31474 effective words/s\n",
      "2024-02-29 15:43:43,352 : INFO : EPOCH 26 - PROGRESS: at 79.95% examples, 29152 words/s, in_qsize 1, out_qsize 0\n",
      "2024-02-29 15:43:43,368 : INFO : EPOCH 26: training on 51200 raw words (37925 effective words) took 1.1s, 35788 effective words/s\n",
      "2024-02-29 15:43:44,228 : INFO : EPOCH 27: training on 51200 raw words (38069 effective words) took 0.9s, 44750 effective words/s\n",
      "2024-02-29 15:43:45,200 : INFO : EPOCH 28: training on 51200 raw words (38037 effective words) took 0.9s, 40422 effective words/s\n",
      "2024-02-29 15:43:46,242 : INFO : EPOCH 29 - PROGRESS: at 80.89% examples, 30393 words/s, in_qsize 1, out_qsize 1\n",
      "2024-02-29 15:43:46,269 : INFO : EPOCH 29: training on 51200 raw words (38157 effective words) took 1.0s, 36628 effective words/s\n",
      "2024-02-29 15:43:47,303 : INFO : EPOCH 30 - PROGRESS: at 100.00% examples, 37135 words/s, in_qsize 0, out_qsize 1\n",
      "2024-02-29 15:43:47,304 : INFO : EPOCH 30: training on 51200 raw words (38140 effective words) took 1.0s, 37101 effective words/s\n",
      "2024-02-29 15:43:48,496 : INFO : EPOCH 31 - PROGRESS: at 80.89% examples, 26845 words/s, in_qsize 1, out_qsize 1\n",
      "2024-02-29 15:43:48,518 : INFO : EPOCH 31: training on 51200 raw words (38223 effective words) took 1.2s, 32595 effective words/s\n",
      "2024-02-29 15:43:49,868 : INFO : EPOCH 32 - PROGRESS: at 79.95% examples, 22969 words/s, in_qsize 1, out_qsize 1\n",
      "2024-02-29 15:43:49,931 : INFO : EPOCH 32: training on 51200 raw words (37981 effective words) took 1.4s, 27378 effective words/s\n",
      "2024-02-29 15:43:51,201 : INFO : EPOCH 33 - PROGRESS: at 80.89% examples, 25254 words/s, in_qsize 1, out_qsize 1\n",
      "2024-02-29 15:43:51,211 : INFO : EPOCH 33: training on 51200 raw words (38168 effective words) took 1.2s, 31015 effective words/s\n",
      "2024-02-29 15:43:52,285 : INFO : EPOCH 34 - PROGRESS: at 80.89% examples, 29656 words/s, in_qsize 1, out_qsize 1\n",
      "2024-02-29 15:43:52,293 : INFO : EPOCH 34: training on 51200 raw words (38130 effective words) took 1.0s, 36528 effective words/s\n",
      "2024-02-29 15:43:53,390 : INFO : EPOCH 35 - PROGRESS: at 80.89% examples, 28668 words/s, in_qsize 1, out_qsize 0\n",
      "2024-02-29 15:43:53,397 : INFO : EPOCH 35: training on 51200 raw words (37907 effective words) took 1.1s, 35246 effective words/s\n",
      "2024-02-29 15:43:54,575 : INFO : EPOCH 36 - PROGRESS: at 79.95% examples, 26459 words/s, in_qsize 1, out_qsize 1\n",
      "2024-02-29 15:43:54,581 : INFO : EPOCH 36: training on 51200 raw words (38180 effective words) took 1.2s, 32873 effective words/s\n",
      "2024-02-29 15:43:55,667 : INFO : EPOCH 37 - PROGRESS: at 79.95% examples, 29337 words/s, in_qsize 1, out_qsize 1\n",
      "2024-02-29 15:43:55,669 : INFO : EPOCH 37: training on 51200 raw words (38036 effective words) took 1.0s, 36569 effective words/s\n",
      "2024-02-29 15:43:56,785 : INFO : EPOCH 38 - PROGRESS: at 79.95% examples, 28731 words/s, in_qsize 1, out_qsize 1\n",
      "2024-02-29 15:43:56,812 : INFO : EPOCH 38: training on 51200 raw words (38265 effective words) took 1.1s, 34912 effective words/s\n",
      "2024-02-29 15:43:57,862 : INFO : EPOCH 39 - PROGRESS: at 80.89% examples, 30117 words/s, in_qsize 1, out_qsize 0\n",
      "2024-02-29 15:43:57,867 : INFO : EPOCH 39: training on 51200 raw words (37942 effective words) took 1.0s, 37064 effective words/s\n",
      "2024-02-29 15:43:57,868 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2048000 raw words (1524288 effective words) took 44.3s, 34379 effective words/s', 'datetime': '2024-02-29T15:43:57.868168', 'gensim': '4.2.0', 'python': '3.8.18 (default, Sep 11 2023, 13:40:15) \\n[GCC 11.2.0]', 'platform': 'Linux-4.19.0-9.ucloud-x86_64-with-glibc2.17', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import sys\n",
    "from ImportantConfig import Config\n",
    "from sql2fea import TreeBuilder, value_extractor\n",
    "from NET import TreeNet\n",
    "from sql2fea import Sql2Vec\n",
    "from TreeLSTM import SPINN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "from PGUtils import pgrunner\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sql_feature.workload_embedder import PredicateEmbedderDoc2Vec\n",
    "\n",
    "sys.path.append('/home/ubuntu/project/HyperQO')\n",
    "\n",
    "config = Config()\n",
    "# sys.stdout = open(config.log_file, \"w\")\n",
    "random.seed(0)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with open(config.queries_file) as f:\n",
    "        import json\n",
    "\n",
    "        queries = json.load(f)\n",
    "\n",
    "    tree_builder = TreeBuilder()\n",
    "    sql2vec = Sql2Vec()\n",
    "    # 这里的 input_size 必须为偶数！\n",
    "    value_network = SPINN(head_num=config.head_num, input_size=36, hidden_size=config.hidden_size, table_num=50,\n",
    "                          sql_size=config.sql_size, attention_dim=30).to(config.device)\n",
    "    for name, param in value_network.named_parameters():\n",
    "        from torch.nn import init\n",
    "\n",
    "        if len(param.shape) == 2:\n",
    "            init.xavier_normal(param)\n",
    "        else:\n",
    "            init.uniform(param)\n",
    "\n",
    "    treenet_model = TreeNet(tree_builder, value_network)\n",
    "\n",
    "    mask = (torch.rand(1, config.head_num, device=config.device) < 0.9).long()\n",
    "\n",
    "    train = pd.read_csv('./information/train.csv', index_col=0)\n",
    "    queries = train['query'].values\n",
    "\n",
    "    workload_embedder = PredicateEmbedderDoc2Vec(queries, 20, pgrunner)\n",
    "\n",
    "    train.head()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-29T07:43:57.891341Z",
     "start_time": "2024-02-29T07:43:57.883437Z"
    }
   },
   "id": "9baf7f906f98d852",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5e69fd-0b70-4f97-b47e-9133a3aa4c91",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-02-29T05:27:30.139255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "len of plan_feature : torch.Size([1, 144])\n",
      "train loss, mean, variance, exp_variance : 0.21124210953712463 - 0.6066794991493225 - 0.43400573059882436 - 1.0\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "len of plan_feature : torch.Size([1, 144])\n",
      "train loss, mean, variance, exp_variance : 0.17283785343170166 - 0.6475439071655273 - 0.3856182430423455 - 1.0\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "feature size : torch.Size([36])\n",
      "len of plan_feature : torch.Size([1, 144])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(train.index)\n",
    "y = torch.tensor(train['cost_reduction_ratio'].values)\n",
    "\n",
    "    # 定义损失函数和优化器\n",
    "criterion = nn.MSELoss()  # 例如，均方误差损失\n",
    "optimizer = treenet_model.optimizer  # 例如，Adam 优化器\n",
    "\n",
    "Batch_Size = 32\n",
    "torch_dataset = Data.TensorDataset(x, y)\n",
    "\n",
    "    # 训练循环\n",
    "run_cnt=1\n",
    "for epoch in range(1):  # 例如，训练多个 epochs\n",
    "    loader = Data.DataLoader(dataset=torch_dataset,\n",
    "                                 batch_size=Batch_Size,\n",
    "                                 shuffle=True)\n",
    "    for batch_x, batch_y in loader:\n",
    "        optimizer.zero_grad()  # 每个批次前先清零梯度\n",
    "        batch_loss = 0\n",
    "        for num in range(Batch_Size):\n",
    "            sql = queries[batch_x[num]]\n",
    "            target_value = batch_y[num]\n",
    "            plan_json = pgrunner.getCostPlanJson(sql)\n",
    "            sql_vec = workload_embedder.get_embedding([sql])\n",
    "\n",
    "                # 计算损失\n",
    "            loss, mean, variance, exp_variance = treenet_model.train(plan_json, sql_vec, target_value, mask,\n",
    "                                                                         is_train=True)\n",
    "            run_cnt+=1\n",
    "            print(\"train loss, mean, variance, exp_variance : {} - {} - {} - {}\".format(loss, mean, variance, exp_variance))\n",
    "                # loss = treenet_model.optimize()\n",
    "\n",
    "            batch_loss += loss  # 累积批次损失\n",
    "            # print(type(batch_loss))\n",
    "        # batch_loss.backward()\n",
    "        # optimizer.step()\n",
    "        \n",
    "            # if run_cnt <1000 or run_cnt%10==0:\n",
    "            #     loss_value, mean, _ = treenet_model.optimize()\n",
    "            #     print(\"optimize loss, mean : {} = {}\".format(loss_value, mean))\n",
    "            #     if mean <= 0.1:\n",
    "            #         break\n",
    "        print(\"batch loss : {}\".format(batch_loss / Batch_Size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f143ea98-7502-4483-aa4d-e68a5acd3c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "treenet_model.plan_to_value()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
